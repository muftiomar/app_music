#!/usr/bin/env python3
"""
Test complet du pipeline music-faker: Producer Kafka -> Consumer HDFS -> Analyse
"""
import subprocess
import time
import sys
import os

def run_command(cmd, description, background=False):
    """ExÃ©cute une commande avec gestion d'erreur"""
    print(f"ğŸ”„ {description}...")
    try:
        if background:
            process = subprocess.Popen(cmd, shell=True)
            return process
        else:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… {description} - SuccÃ¨s")
                return result
            else:
                print(f"âŒ {description} - Erreur: {result.stderr}")
                return None
    except Exception as e:
        print(f"âŒ {description} - Exception: {e}")
        return None

def test_kafka_connectivity():
    """Test la connectivitÃ© Kafka"""
    print("\nğŸ“¡ TEST DE CONNECTIVITÃ‰ KAFKA")
    print("-" * 40)
    
    # VÃ©rifier les conteneurs Kafka
    result = run_command("docker ps | grep kafka", "VÃ©rification conteneur Kafka")
    if not result or not result.stdout.strip():
        print("âŒ Kafka n'est pas en cours d'exÃ©cution")
        return False
    
    print("âœ… Kafka est actif")
    return True

def test_hdfs_connectivity():
    """Test la connectivitÃ© HDFS"""
    print("\nï¿½ TEST DE CONNECTIVITÃ‰ HDFS")
    print("-" * 40)
    
    # VÃ©rifier le namenode
    result = run_command("docker ps | grep namenode", "VÃ©rification namenode HDFS")
    if not result or not result.stdout.strip():
        print("âŒ HDFS namenode n'est pas en cours d'exÃ©cution")
        return False
    
    print("âœ… HDFS est opÃ©rationnel")
    return True

def run_pipeline_test(num_events=20):
    """ExÃ©cute un test complet du pipeline"""
    print(f"\nğŸµ TEST COMPLET DU PIPELINE - {num_events} Ã‰VÃ‰NEMENTS")
    print("=" * 60)
    
    # Ã‰tape 1: Lancer le consumer en arriÃ¨re-plan
    print("\nğŸ”½ DÃ©marrage du consumer HDFS...")
    consumer_process = subprocess.Popen([
        "python", "consumer/kafka_hdfs_consumer.py", "-m", "batch", "-b", "5"
    ], cwd="/Users/omar/Desktop/datalake/app_music/music-faker")
    
    # Attendre un peu que le consumer dÃ©marre
    time.sleep(3)
    
    # Ã‰tape 2: GÃ©nÃ©rer des Ã©vÃ©nements avec le producer
    print(f"\nğŸ”¼ GÃ©nÃ©ration de {num_events} Ã©vÃ©nements musicaux...")
    producer_cmd = f"python producer/music_producer.py -n {num_events} -d 0.1"
    producer_result = run_command(
        f"cd /Users/omar/Desktop/datalake/app_music/music-faker && {producer_cmd}",
        f"Production de {num_events} Ã©vÃ©nements"
    )
    
    if not producer_result:
        consumer_process.terminate()
        return False
    
    # Ã‰tape 3: Attendre que le consumer traite tous les Ã©vÃ©nements
    print("\nâ³ Attente du traitement par le consumer (15 secondes)...")
    time.sleep(15)
    
    # Ã‰tape 4: ArrÃªter le consumer
    print("\nğŸ›‘ ArrÃªt du consumer...")
    consumer_process.terminate()
    consumer_process.wait()
    
    # Ã‰tape 5: VÃ©rifier les donnÃ©es dans HDFS
    print("\nğŸ” VÃ©rification des donnÃ©es dans HDFS...")
    hdfs_check_cmd = "docker exec namenode hdfs dfs -ls -R /music_events/ | grep batch"
    result = run_command(hdfs_check_cmd, "Listage des fichiers HDFS")
    
    if result and result.stdout.strip():
        files = result.stdout.strip().split('\n')
        print(f"âœ… {len(files)} fichiers trouvÃ©s dans HDFS")
        return True
    else:
        print("âŒ Aucun fichier trouvÃ© dans HDFS")
        return False

def run_analytics_test():
    """Test l'analyseur de donnÃ©es"""
    print("\nğŸ“ˆ TEST DE L'ANALYSEUR DE DONNÃ‰ES")
    print("-" * 40)
    
    analytics_cmd = "python analytics/music_analyzer.py"
    result = run_command(
        f"cd /Users/omar/Desktop/datalake/app_music/music-faker && {analytics_cmd}",
        "ExÃ©cution de l'analyseur"
    )
    
    return result is not None

def main():
    """Test principal"""
    print("ğŸš€ TEST COMPLET DU PIPELINE MUSIC-FAKER")
    print("=" * 50)
    
    # Tests de connectivitÃ©
    kafka_ok = test_kafka_connectivity()
    hdfs_ok = test_hdfs_connectivity()
    
    if not (kafka_ok and hdfs_ok):
        print("\nâŒ Les prÃ©requis ne sont pas satisfaits")
        sys.exit(1)
    
    # Test du pipeline complet
    pipeline_ok = run_pipeline_test(num_events=25)
    
    # Test de l'analyseur
    analytics_ok = run_analytics_test()
    
    # RÃ©sumÃ© final
    print("\n" + "=" * 60)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DES TESTS")
    print("=" * 60)
    print(f"   ğŸ”— ConnectivitÃ© Kafka: {'âœ…' if kafka_ok else 'âŒ'}")
    print(f"   ğŸ’¾ ConnectivitÃ© HDFS: {'âœ…' if hdfs_ok else 'âŒ'}")
    print(f"   ğŸ”„ Pipeline complet: {'âœ…' if pipeline_ok else 'âŒ'}")
    print(f"   ğŸ“Š Analyseur: {'âœ…' if analytics_ok else 'âŒ'}")
    
    if kafka_ok and hdfs_ok and pipeline_ok and analytics_ok:
        print("\nğŸ‰ TOUS LES TESTS SONT PASSÃ‰S AVEC SUCCÃˆS!")
        print("\nâœ¨ Le pipeline music-faker est entiÃ¨rement opÃ©rationnel:")
        print("   â€¢ Producer Kafka âœ…")
        print("   â€¢ Consumer HDFS âœ…") 
        print("   â€¢ Stockage partitionnÃ© âœ…")
        print("   â€¢ Analyseur de donnÃ©es âœ…")
    else:
        print("\nâš ï¸  Certains tests ont Ã©chouÃ©")

if __name__ == "__main__":
    main()
