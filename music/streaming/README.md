# ğŸŒŠ Streaming & Kafka

## ğŸ¯ Objectif
GÃ©rer le flux de donnÃ©es en temps rÃ©el entre les producers et le stockage via Kafka et Spark Streaming.

## ğŸ“‹ TÃ¢ches principales
- [ ] Configuration et dÃ©ploiement de Kafka
- [ ] Consumer Spark Streaming pour ingestion
- [ ] Gestion des erreurs et retry logic
- [ ] Monitoring du pipeline streaming

## ğŸ› ï¸ Technologies
- Apache Kafka
- Spark Streaming (PySpark)
- Docker Compose pour Kafka
- Kafka Manager pour monitoring

## ğŸ“ Structure des fichiers
```
streaming/
â”œâ”€â”€ kafka_config/
â”‚   â”œâ”€â”€ docker-compose.yml     # Cluster Kafka
â”‚   â””â”€â”€ server.properties      # Configuration Kafka
â”œâ”€â”€ spark_consumer.py          # Consumer Spark Streaming
â”œâ”€â”€ monitoring.py              # MÃ©triques et alertes
â”œâ”€â”€ error_handler.py           # Gestion des erreurs
â””â”€â”€ requirements.txt           # DÃ©pendances Python
```

## ğŸš€ Quick Start
```bash
cd streaming/
docker-compose up -d           # DÃ©marrer Kafka
python spark_consumer.py       # Lancer le consumer
```

## ğŸ“Š Topics Kafka
- `music-events`: Ã‰vÃ©nements d'Ã©coute principaux
- `user-interactions`: Likes, partages, playlists
- `system-metrics`: MÃ©triques de performance
