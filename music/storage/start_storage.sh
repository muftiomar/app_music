#!/bin/bash

# Script de dÃ©marrage pour le composant Storage/HDFS
echo "ğŸ—„ï¸  DÃ©marrage du composant Storage HDFS"
echo "======================================"

# VÃ©rifier si Python est installÃ©
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 n'est pas installÃ©"
    exit 1
fi

# Aller dans le rÃ©pertoire storage
cd "$(dirname "$0")"
echo "ğŸ“ RÃ©pertoire: $(pwd)"

# VÃ©rifier si Docker est en cours d'exÃ©cution
if ! docker info &> /dev/null; then
    echo "âš ï¸  Docker n'est pas en cours d'exÃ©cution"
    echo "   Veuillez dÃ©marrer Docker avant de continuer"
    exit 1
fi

# VÃ©rifier le statut de Hadoop
echo "ğŸ” VÃ©rification du statut Hadoop..."
if docker ps | grep -q namenode; then
    echo "âœ… Hadoop Namenode est en cours d'exÃ©cution"
    HADOOP_RUNNING=true
else
    echo "âš ï¸  Hadoop Namenode n'est pas en cours d'exÃ©cution"
    HADOOP_RUNNING=false
fi

echo ""
echo "Options disponibles:"
echo "1. ğŸ³ DÃ©marrer l'infrastructure Hadoop (Docker)"
echo "2. ğŸ—„ï¸  CrÃ©er la structure HDFS"
echo "3. ğŸ“Š CrÃ©er les tables Hive"
echo "4. ğŸ§ª Test d'ingestion de donnÃ©es"
echo "5. ğŸ“ GÃ©nÃ©rer des donnÃ©es d'exemple"
echo "6. ğŸ” VÃ©rifier le statut HDFS"
echo "7. ğŸ›‘ ArrÃªter Hadoop"

read -p "Votre choix (1-7): " choice

case $choice in
    1)
        echo "ğŸ³ DÃ©marrage de l'infrastructure Hadoop..."
        cd ../../
        docker-compose up -d namenode datanode
        echo "â³ Attente du dÃ©marrage complet (30s)..."
        sleep 30
        echo "âœ… Infrastructure Hadoop dÃ©marrÃ©e"
        echo "ğŸŒ Interface web disponible: http://localhost:9870"
        ;;
    2)
        echo "ğŸ—„ï¸  CrÃ©ation de la structure HDFS..."
        python3 -c "
from hdfs_manager import HDFSManager
hdfs = HDFSManager()
success = hdfs.create_directory_structure()
print('âœ… Structure crÃ©Ã©e avec succÃ¨s' if success else 'âŒ Ã‰chec crÃ©ation structure')
hdfs.close()
"
        ;;
    3)
        echo "ğŸ“Š CrÃ©ation des tables Hive..."
        if [ "$HADOOP_RUNNING" = true ]; then
            docker exec -i namenode hive -f /myhadoop/music/storage/hive_schemas.sql
        else
            echo "âŒ Hadoop n'est pas dÃ©marrÃ©. Utilisez l'option 1 d'abord."
        fi
        ;;
    4)
        echo "ğŸ§ª Test d'ingestion de donnÃ©es..."
        python3 data_ingestion.py
        ;;
    5)
        echo "ğŸ“ GÃ©nÃ©ration de donnÃ©es d'exemple..."
        python3 -c "
from data_ingestion import DataIngestionTester
tester = DataIngestionTester()
tester.test_with_sample_files()
"
        ;;
    6)
        echo "ğŸ” VÃ©rification du statut HDFS..."
        python3 -c "
from hdfs_manager import HDFSManager
hdfs = HDFSManager()
print(f'HDFS connectÃ©: {hdfs.fs is not None}')
print(f'Spark disponible: {hdfs.spark is not None}')
tables = hdfs.list_tables()
print(f'Tables configurÃ©es: {len(tables)}')
for table in tables:
    info = hdfs.get_table_info(table)
    print(f'  - {table}: {info.get(\"exists\", \"unknown\")}')
hdfs.close()
"
        ;;
    7)
        echo "ğŸ›‘ ArrÃªt de Hadoop..."
        cd ../../
        docker-compose stop namenode datanode
        echo "âœ… Hadoop arrÃªtÃ©"
        ;;
    *)
        echo "âŒ Choix invalide"
        exit 1
        ;;
esac

echo ""
echo "âœ… OpÃ©ration terminÃ©e"
echo "ğŸ“‹ Pour plus d'infos, consultez: music/storage/README.md"
