# TODO - R√©partition des T√¢ches

## R√©partition Sugg√©r√©e par Composant

### üë§ Personne 1 - Producer & Kafka
**Dossier** : `producer/`
**Responsabilit√©s** :
- Cr√©er le simulateur d'√©v√©nements musicaux
- Configurer Kafka
- G√©n√©rer des donn√©es r√©alistes (√©coutes, likes, partages)
- Format des √©v√©nements JSON

### üë§ Personne 2 - Consumer & Streaming
**Dossier** : `consumer/`
**Responsabilit√©s** :
- D√©velopper le consumer Spark Streaming
- Ingestion depuis Kafka vers HDFS
- Nettoyage et enrichissement des donn√©es
- Gestion des erreurs et monitoring

### üë§ Personne 3 - Traitement Batch
**Dossier** : `batch_processing/`
**Responsabilit√©s** :
- Scripts Spark SQL / Hive
- Calcul des m√©triques analytiques
- Optimisation des requ√™tes
- Sauvegarde des r√©sultats

### üë§ Personne 4 - Frontend & API
**Dossier** : `frontend/`
**Responsabilit√©s** :
- Interface web (Flask ou React)
- API pour servir les m√©triques
- Graphiques et visualisations
- Design et UX

### üë§ Personne 5 - Architecture & Documentation
**Dossier** : `docs/`
**Responsabilit√©s** :
- Justification choix d'architecture (Partie 1)
- Sch√©mas et diagrammes (Partie 2)
- Documentation technique
- Coordination g√©n√©rale

## Fichiers √† Cr√©er par √âquipe

### Producer (Personne 1)
- [ ] `producer/music_event_generator.py`
- [ ] `producer/kafka_producer.py`
- [ ] `producer/config.py`

### Consumer (Personne 2)
- [ ] `consumer/spark_streaming_consumer.py`
- [ ] `consumer/data_cleaner.py`
- [ ] `consumer/hdfs_writer.py`

### Batch Processing (Personne 3)
- [ ] `batch_processing/metrics_calculator.py`
- [ ] `batch_processing/spark_jobs.py`
- [ ] `batch_processing/hive_queries.sql`

### Frontend (Personne 4)
- [ ] `frontend/app.py` (Flask) ou setup React
- [ ] `frontend/api.py`
- [ ] `frontend/templates/` ou `frontend/src/`

### Documentation (Personne 5)
- [ ] `docs/architecture_choice.md`
- [ ] `docs/pipeline_schema.md`
- [ ] `docs/setup_instructions.md`

## Coordination

### Points de Synchronisation
1. **Format des donn√©es** : Le Producer doit d√©finir le sch√©ma JSON
2. **API des m√©triques** : Batch Processing et Frontend doivent s'accorder
3. **Configuration** : Partager les configs Kafka, HDFS, etc.

### R√©unions Sugg√©r√©es
- [ ] Kick-off : D√©finir les formats de donn√©es
- [ ] Mi-parcours : V√©rifier l'int√©gration
- [ ] Finale : Tests end-to-end
